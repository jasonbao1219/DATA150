I enjoyed, and have learned a lot about neural network, transfer learning, stack generalization, and data science in general from Clare’s Slice of Data Science presentation. Even through I only barely touches the tip of the iceberg of agent-based modeling in my DATA 150 class, her detailed while interesting lecture are essential to make the presentation enjoyable. Moreover, I really liked the use of her own projects as examples: the familiarity is unparalleled. 

Clare first introduced neural network to us. It is one (of many) machine learning models that can be used by data scientists to classify data. The three layers of hidden layer, input layer, and output layer construct a process that is able to predict the output from the input data. How neural network works is first transforming data to one-dimensional vectors; then, trained weights are applied for manipulation; finally predictions are made. In the Spotify example, she showed us how factors such as acoustics and liveness contribute to the network’s overall prediction of music genre. Next, Clare moved on and talked about convolutional networks, which is a special type of neural network that identify images by breaking them into matrixes and numbers. 

The second main topic of Clare’s presentation is transfer learning. Basically, it allows us to take pre-trained models and weights from the Python Library and manipulate it in order to solve one’s specific problem or address a particular need. The example she gave here is a road quality identification model based on data from satellite images. Classifiers are central in transfer learning because it is really important to remove the default classifier and customize classifier according to the needs. Transfer Learning is really useful by saving a lot of time and energy since pre-trained weights can be taken from the library directly. 

Last but not last, Clare introduced stacked generalization, which is my favorite technique that I have learned so far in data science. Clare presented the concept smoothly as she utilizes audiences as examples, asking them to act like models to predict (identify) low-resolution images. It really is what stacked generalization all about as stacked generalization is a large model that collects votes from sub-models based on their individual prediction, generalizes the votes and produces the outcome. She also mentioned that models and algorithms also have strengths and weaknesses in predicting different objects, and bias or favor is sometimes needed for a specific algorithm that researchers believe will be helpful. 

From this presentation, I have gained many insights of data science that I have never learned before. It has demonstrated to me that programming is the center of data science, as well as showed me various ways that data science technologies can be applied in the real world to solve practical problems. I have seen both the interesting part and the complex part of data science in this presentation; and I really appreciate it.
